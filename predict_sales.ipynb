{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Sales competition\n",
    "## Goal is to predict total sales for every product for the next month\n",
    "I did not take the coursera course associated with this contest but I thought I'd give it a shot. \n",
    "Code that is commented out is likely something I ran in console to personally view but not worth visualizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "import umap\n",
    "import shap\n",
    "import tensorflow as tf\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('.\\\\data\\\\sales_train.csv')\n",
    "df_test = pd.read_csv('.\\\\data\\\\test.csv')\n",
    "items = pd.read_csv('.//data/items.csv')\n",
    "item_categories = pd.read_csv('.//data/item_categories.csv')\n",
    "shops = pd.read_csv('.//data/shops.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing & Exploration\n",
    "The preprocessing for the test data will be done alongside the training data  \n",
    "Begin with joining the lookup tables to the main table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()\n",
    "#df.count()\n",
    "#df.describe()\n",
    "#item_categories.head()\n",
    "#items.head()\n",
    "#shops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joining the lookup tables by passing a list of them with their indexes set to their respective id columns\n",
    "df = df.merge(items, left_on='item_id',right_on='item_id')            \n",
    "df = df.merge(item_categories, left_on='item_category_id',right_on='item_category_id')\n",
    "df = df.merge(shops, left_on='shop_id',right_on='shop_id')\n",
    "#df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.merge(items, left_on='item_id',right_on='item_id')            \n",
    "df_test = df_test.merge(item_categories, left_on='item_category_id',right_on='item_category_id')\n",
    "df_test = df_test.merge(shops, left_on='shop_id',right_on='shop_id')\n",
    "#df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Won't be able to easily interpret the names for items, shops, or item categories because they are in Russian but they will be useful for visualizing the data\n",
    "  \n",
    "I originally tried to use the join function to match what I would have done in SQL but it would not do one to many matches and left many null values. Doing the merges one table at a time is a little tedious and repetitive so I will see if there is a better way to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date parts column engineering\n",
    "we need to get the month, year, and day separately from the date  \n",
    "also what is the date_block_num column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['date'][0])\n",
    "#date is by string, so I can split by the period for each date part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create columns for each date part\n",
    "df['day'] = df['date'].apply(lambda x: x.split('.')[0])\n",
    "df['month'] = df['date'].apply(lambda x: x.split('.')[1])\n",
    "df['year'] = df['date'].apply(lambda x: x.split('.')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20949    31340\n",
       "5822      9408\n",
       "17717     9067\n",
       "2808      7479\n",
       "4181      6853\n",
       "Name: item_id, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Want to see the total sales by month for every product, so lets start with a single product\n",
    "df['item_id'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The top product will do for our sample\n",
    "df_s = df[df['item_id'] == 20949]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
